{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lin_Reg: 0.491938720496\n",
      "Log_Reg: 0.412026726058\n",
      "DTC: 0.336302895323\n",
      "KNC: 0.398663697105\n",
      "LDA: 0.516703786192\n",
      "GNB: 0.556792873051\n",
      "BR: 0.491023182681\n",
      "EN: 0.0968876481818\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, SVR\n",
    "%matplotlib inline\n",
    "\n",
    "# import file\n",
    "data = pd.read_csv('facies_vectors.csv')\n",
    "\n",
    "# fill NaN with the mean value\n",
    "data.fillna(data['PE'].mean(), inplace=True)\n",
    "\n",
    "# create a raining wells set of data (without test well)\n",
    "training_wells = data[data['Well Name'] != 'SHANKLE']\n",
    "\n",
    "# create a test well set of data\n",
    "test_well = data[data['Well Name'] == 'SHANKLE']\n",
    "\n",
    "# unique training well names\n",
    "well_names = list(training_wells['Well Name'].unique())\n",
    "\n",
    "# create a list of features from training wells (without Facies)\n",
    "X_train = np.array(training_wells.drop(['Facies', 'Formation', 'Well Name', \n",
    "                                        'Depth', 'NM_M', 'RELPOS'], 1))\n",
    "\n",
    "# create a label from training wells (Facies)\n",
    "y_train = np.array(training_wells['Facies'])\n",
    "\n",
    "# create a list of features from test well (without Facies)\n",
    "X_test = np.array(test_well.drop(['Facies', 'Formation', 'Well Name', \n",
    "                                  'Depth', 'NM_M', 'RELPOS'], 1))\n",
    "\n",
    "# create a label from test well (Facies)\n",
    "y_test = np.array(test_well['Facies'])\n",
    "\n",
    "models = []\n",
    "models.append(('Lin_Reg', LinearRegression()))\n",
    "models.append(('Log_Reg', LogisticRegression()))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "models.append(('KNC', KNeighborsClassifier()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('BR', BayesianRidge()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    names.append(name)\n",
    "    results.append(model.score(X_test, y_test))\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(\"%s: %s\" % (names[i], results[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's count the number of each facies in the test well SHANKLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 89, 2: 89, 3: 117, 4: 7, 5: 19, 6: 71, 7: 17, 8: 40}\n"
     ]
    }
   ],
   "source": [
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# 1=sandstone  2=c_siltstone   3=f_siltstone  # 4=marine_silt_shale \n",
    "# 5=mudstone 6=wackestone 7=dolomite 8=packstone 9=bafflestone\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "\n",
    "facies_titles = ['sandstone', 'c_siltstone', 'f_siltstone', 'marine_silt_shale',\n",
    "                'mudstone', 'wackestone', 'dolomite', 'packstone', 'bafflestone']\n",
    "\n",
    "facies_color_map = dict(zip(facies_labels, facies_colors))\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i in y_test:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "    \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60 19  5  0  0  5  0  0  0]\n",
      " [24 51  9  0  0  5  0  0  0]\n",
      " [ 0 44 67  0  1  4  0  1  0]\n",
      " [ 0  0  0  1  0  6  0  0  0]\n",
      " [ 0  0  0  9  0 10  0  0  0]\n",
      " [ 0  0  1  5  4 50  0 10  1]\n",
      " [ 4  1  1  1  0  0  4  6  0]\n",
      " [ 0  0  1  6  0 16  0 17  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "prediction_GNB = GNB.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, prediction_GNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's check confusion matrix with other algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 85  1  0  0  3  0  0]\n",
      " [ 0 80  6  0  0  2  0  1]\n",
      " [ 0 51 57  0  0  4  0  5]\n",
      " [ 0  1  0  0  0  6  0  0]\n",
      " [ 0  2  0  6  0  8  0  3]\n",
      " [ 0 13  1  2  0 22  0 33]\n",
      " [ 0  9  7  0  0  0  0  1]\n",
      " [ 0  2  0  1  0 11  0 26]]\n",
      "------------------------------\n",
      "[[ 4 55 11  9  3  4  0  2  1]\n",
      " [17 31 20  7  2  7  1  4  0]\n",
      " [ 4 39 52  5  7  3  3  4  0]\n",
      " [ 0  0  0  0  0  6  0  1  0]\n",
      " [ 0  0  0 11  0  2  0  5  1]\n",
      " [ 0  2  2  3 10 40  1 13  0]\n",
      " [ 2  0  0  1  3  1  4  6  0]\n",
      " [ 0  1  0  1  3  7  1 23  4]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n",
      "------------------------------\n",
      "[[32 42  7  4  1  0  0  3  0]\n",
      " [13 47 20  4  0  3  0  1  1]\n",
      " [ 6 48 52  2  5  1  2  1  0]\n",
      " [ 0  5  0  0  0  2  0  0  0]\n",
      " [ 0  3  0  6  1  0  2  7  0]\n",
      " [ 1  5  2  2  7 31  3 18  2]\n",
      " [ 2  0  1  0  0  1  3  9  1]\n",
      " [ 0  1  0  2  2 12  6 13  4]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n",
      "------------------------------\n",
      "[[31 55  1  0  0  2  0  0  0]\n",
      " [ 1 76  6  0  0  5  0  1  0]\n",
      " [ 0 49 59  0  0  5  0  4  0]\n",
      " [ 0  0  1  0  0  5  0  1  0]\n",
      " [ 0  3  0  9  0  5  0  2  0]\n",
      " [ 0  9  1  5  3 42  0 11  0]\n",
      " [ 0 11  6  0  0  0  0  0  0]\n",
      " [ 0  2  0  2  0 11  0 24  1]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "prediction_Log_Reg = Log_Reg.predict(X_test)\n",
    "prediction_DTC = DTC.predict(X_test)\n",
    "prediction_KNC = KNC.predict(X_test)\n",
    "prediction_LDA = LDA.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, prediction_Log_Reg))\n",
    "print(\"-\" * 30)\n",
    "print(confusion_matrix(y_test, prediction_DTC))\n",
    "print(\"-\" * 30)\n",
    "print(confusion_matrix(y_test, prediction_KNC))\n",
    "print(\"-\" * 30)\n",
    "print(confusion_matrix(y_test, prediction_LDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# describe the main statistical distribution of the input variables\n",
    "training_wells.describe()\n",
    "\n",
    "training_wells.groupby('Facies').size()\n",
    "\n",
    "training_wells.plot(kind='box', subplots=True, layout=(3, 3), figsize=(7, 7), \n",
    "                    fontsize=8, sharex=False, sharey=False)\n",
    "plt.show()\n",
    "\n",
    "training_wells.hist(figsize=(7, 7))\n",
    "plt.show()\n",
    "\n",
    "scatter_matrix(training_wells)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out all the empty values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ALL TRAINING WELLS\n",
    "fig = plt.figure(figsize=(20, 10)) \n",
    "\n",
    "# (1, 5, 1) stands for (from, to, where)\n",
    "ax1 = fig.add_subplot(1, 5, 1)\n",
    "ax1.scatter(data['GR'], data['Depth'], color='r', alpha=0.5)\n",
    "ax1.set_ylabel('Depth', fontsize = '14' )\n",
    "ax1.set_xlabel('GR', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax2 = fig.add_subplot(1, 5, 2)\n",
    "ax2.scatter(data['ILD_log10'], data['Depth'], color = 'g', alpha=0.5)\n",
    "ax2.set_xlabel('ILD_log10', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax3 = fig.add_subplot(1, 5, 3)\n",
    "ax3.scatter(data['DeltaPHI'], data['Depth'], color = 'r', alpha=0.5)\n",
    "ax3.set_xlabel('DeltaPHI', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax4 = fig.add_subplot(1, 5, 4)\n",
    "ax4.scatter(data['PHIND'], data['Depth'], color = 'k', alpha=0.5)\n",
    "ax4.set_xlabel('PHIND', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax4 = fig.add_subplot(1, 5, 5)\n",
    "ax4.scatter(data['PE'], data['Depth'], color = 'k', alpha=0.5)\n",
    "ax4.set_xlabel('PE', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lokking for GR extremums\n",
    "num = 0\n",
    "for i in training_wells['GR']:\n",
    "    if i >= 150:\n",
    "        print(i, facies_titles[data['Facies'][num]])\n",
    "    num += 1\n",
    "    \n",
    "    \n",
    "\n",
    "#num = 0\n",
    "#for i in training_wells['GR']:\n",
    "#    if i >= 150:\n",
    "#        print('GR %d  -->  %d m  -->  %s' % (i, training_wells['Depth'][num], facies_titles[training_wells['Facies'][num]]))\n",
    "#    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SHRIMPLIN WELL\n",
    "SW = data[data['Well Name'] == 'SHRIMPLIN']\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10)) \n",
    "\n",
    "# (1, 5, 1) stands for (from, to, where)\n",
    "ax1 = fig.add_subplot(1, 5, 1)\n",
    "ax1.scatter(SW['GR'], SW['Depth'], color='r', alpha=0.5)\n",
    "ax1.set_ylabel('Depth', fontsize = '14' )\n",
    "ax1.set_xlabel('GR', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax2 = fig.add_subplot(1, 5, 2)\n",
    "ax2.scatter(SW['ILD_log10'], SW['Depth'], color = 'g', alpha=0.5)\n",
    "ax2.set_xlabel('ILD_log10', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax3 = fig.add_subplot(1, 5, 3)\n",
    "ax3.scatter(SW['DeltaPHI'], SW['Depth'], color = 'r', alpha=0.5)\n",
    "ax3.set_xlabel('DeltaPHI', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax4 = fig.add_subplot(1, 5, 4)\n",
    "ax4.scatter(SW['PHIND'], SW['Depth'], color = 'k', alpha=0.5)\n",
    "ax4.set_xlabel('PHIND', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax4 = fig.add_subplot(1, 5, 5)\n",
    "ax4.scatter(SW['PE'], SW['Depth'], color = 'k', alpha=0.5)\n",
    "ax4.set_xlabel('PE', fontsize = '14')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SHRIMPLIN WELL: looking for the GR extremums, its Depth and Facies\n",
    "num = 0\n",
    "for i in SW['GR']:\n",
    "    if i >= 150:\n",
    "        print('GR %d --> %d m --> %s' % (i, float(SW['Depth'][num]), facies_titles[SW['Facies'][num]]))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Performed in cooperation with Ievgen Ustenko\n",
    "Github: https://github.com/iUstenko |\n",
    "LinkedIn: https://goo.gl/gfRoSc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
